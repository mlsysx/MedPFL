{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEufuagtFeWC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from zipfile import ZipFile\n",
    "import zipfile\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1680817482642,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "NWa7Xo6PkIl3",
    "outputId": "95b266ff-3c08-4677-811f-819c791c0a43"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn.functional as func\n",
    "#torch.manual_seed(50)\n",
    "\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "\n",
    "#print (torch.cuda.get_device_name(device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5TMtqJdZetl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1680818849164,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "fY2Lh4vdFuRs",
    "outputId": "8857b0f5-b4e0-45b2-d02d-641b38e704a0"
   },
   "outputs": [],
   "source": [
    "data_dir = 'Brain-Tumor-MRI-Dataset'\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/Training\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrBNxg-UFzdK"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxF2MSTM8NCo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juYIupfd8N3H"
   },
   "source": [
    "Checking **mean** and **SD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxsM6LaXF2wH"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "tp = transforms.Compose([\n",
    "    #transforms.Resize(32),\n",
    "    #transforms.CenterCrop(32),\n",
    "    transforms.Resize((32,32)),\n",
    "    \n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize((0.7160, 0.5668, 0.5441), (0.2207, 0.2087, 0.2222)),\n",
    "    #transforms.Grayscale(num_output_channels=1)\n",
    "])\n",
    "tt = transforms.ToPILImage()\n",
    "\n",
    "dataset = ImageFolder(data_dir+'/Training', transform=tp)\n",
    "#dataset1 = DataLoader(trainset, shuffle=True, batch_size=batch_size, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680819090658,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "c7bd7A_DG-Fi",
    "outputId": "c19fde38-16be-4144-9700-37bc331add6a"
   },
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680819091171,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "lA5d0sjuG-IS",
    "outputId": "0d59a65e-f0ed-47b6-97c5-87ec087146e4"
   },
   "outputs": [],
   "source": [
    "img, label = dataset[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1680819093964,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "IftTKCBYG-Ks",
    "outputId": "70ac5559-e6cd-40ca-a35c-8c6411c9e087"
   },
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1680819094107,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "0ohRjuWCIFkM",
    "outputId": "b96f7bf4-5aa2-42ba-a356-99fbee498f6d"
   },
   "outputs": [],
   "source": [
    "img_na = img.numpy()\n",
    "print(type(img))\n",
    "print(type(img_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4Sz6xX7bi2J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1680819095131,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "vLNkY2BFG-NO",
    "outputId": "c97a8edb-1894-44a8-9ae7-96c5b2fdfba2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img.permute(1, 2, 0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pyn2gTaFG-Qp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1H8Okh4nJ2mS"
   },
   "outputs": [],
   "source": [
    "#from PIL import Image\n",
    "#img_data=[]\n",
    "#images=os.listdir('/content/sample_data/Covid')\n",
    "#for img in images:\n",
    "#  image_arr= cv2.imread(os.path.join('/content/sample_data/Covid',img))\n",
    "#  \n",
    "#  img_data.append(image_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1680819098889,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "FeL26InQhyXU",
    "outputId": "c1a63813-5505-4a40-b282-e092b82440b8"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDiu0MGzYE33"
   },
   "outputs": [],
   "source": [
    "image_data=[]\n",
    "target=[]\n",
    "for i, j in dataset:\n",
    "  image_data.append(i)\n",
    "  target.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1680819101607,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "VhuQ1KKHYqtJ",
    "outputId": "ae169528-0a59-49d7-87e1-289a44c267c6"
   },
   "outputs": [],
   "source": [
    "image_data1=torch.stack(image_data)\n",
    "image_data2=image_data1.numpy()\n",
    "image_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680819103660,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "cPZiYw99m7QG",
    "outputId": "0fe6bde0-4b15-4f62-c7c3-6404ef7ab24b"
   },
   "outputs": [],
   "source": [
    "qq=np.rollaxis(image_data2,1,4)\n",
    "qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1680819104358,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "g-YfTRPcckJC",
    "outputId": "cce95f9f-db69-4af7-b4bd-5d46df2f641f"
   },
   "outputs": [],
   "source": [
    "#plt.imshow(qq[555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_P1t3Vr4hMA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1680819109328,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "ghly_ATKB82z",
    "outputId": "19889cf8-64ff-4ce3-dbcd-78b1bfeac926"
   },
   "outputs": [],
   "source": [
    "# dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
    "# dst = datasets.MNIST(\"~/.torch\", download=True)\n",
    "\n",
    "# tp = transforms.Compose([\n",
    "#     #transforms.Resize(32),\n",
    "#     #transforms.CenterCrop(32),\n",
    "#     transforms.Resize((32,32)),\n",
    "#     transforms.ToTensor(), transforms.Grayscale(num_output_channels=1)\n",
    "# ])\n",
    "# tt = transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "print(\"Running on %s\" % device)\n",
    "\n",
    "def label_to_onehot(target, num_classes=4):\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "    onehot_target.scatter_(1, target, 1)\n",
    "    return onehot_target\n",
    "\n",
    "def cross_entropy_for_onehot(pred, target):\n",
    "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AorI020iVjjS"
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.5, 0.5)\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         #m.bias.data.uniform_(-0.5, 0.5)\n",
    "#         #nn.init.xavier_uniform(m.bias.data)\n",
    "#         m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "# class LeNet(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "\n",
    "#         super(LeNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, kernel_size=5,stride=2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=2)\n",
    "#         self.fc1 = nn.Linear(16*5*5, 256)\n",
    "#         self.fc2 = nn.Linear(256, 120)\n",
    "#         self.fc3 = nn.Linear(120, 106)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #x = func.relu(self.conv1(x))\n",
    "#         x = func.sigmoid(self.conv1(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         #x = func.relu(self.conv2(x))\n",
    "#         x = func.sigmoid(self.conv2(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         #x = func.relu(self.fc1(x))\n",
    "#         x = func.sigmoid(self.fc1(x))\n",
    "#         #x = func.relu(self.fc2(x))\n",
    "#         x = func.sigmoid(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "    \n",
    "    \n",
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.3, 0.3)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         m.bias.data.uniform_(-0.3, 0.3)\n",
    "\n",
    "torch.manual_seed(50)\n",
    "\n",
    "def weights_init(m):\n",
    "    if hasattr(m, \"weight\"):\n",
    "        m.weight.data.uniform_(-0.5, 0.5)\n",
    "    if hasattr(m, \"bias\"):\n",
    "        m.bias.data.uniform_(-0.5, 0.5)\n",
    "        \n",
    "def weights_init_dropout(m):\n",
    "    if hasattr(m, \"weight\"):\n",
    "        m.weight.data.uniform_(-0.1, 0.1)\n",
    "    if hasattr(m, \"bias\"):\n",
    "        m.bias.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        #act = nn.Tanh\n",
    "        #act = nn.ReLU\n",
    "        #act = nn.Softmax\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=2, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(16, 16, kernel_size=2, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(16, 16, kernel_size=2, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(16, 16, kernel_size=2, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(16, 16, kernel_size=2, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(16, 16, kernel_size=2, padding=5//2, stride=1),\n",
    "            act(),\n",
    "           \n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(40000, 4)\n",
    "                # nn.Dropout(p=0.0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "net = LeNet().to(device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "\n",
    "# class LeNet_att(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LeNet_att, self).__init__()\n",
    "#         act = nn.Sigmoid\n",
    "#         #act = nn.Tanh\n",
    "#         #act = nn.ReLU\n",
    "#         self.body = nn.Sequential(\n",
    "#             nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "#             act(),\n",
    "#             nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "#             act(),\n",
    "#             nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "#             act(),\n",
    "#             nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "#             act(),\n",
    "#         )\n",
    "#         self.fc = nn.Sequential(\n",
    "#                 nn.Linear(768, 106)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.body(x)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         # print(out.size())\n",
    "#         out = self.fc(out)\n",
    "#         return out\n",
    "\n",
    "# net_att = LeNet_att().to(device)\n",
    "# net_att.apply(weights_init_dropout)\n",
    "    \n",
    "#criterion = cross_entropy_for_onehot\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(net)\n",
    "# for name, param in net.named_parameters():\n",
    "#     print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1680819113154,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "uptx3bNxB822",
    "outputId": "8d242d8e-66a6-4723-b26b-f7ef8d3a92bf"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "#from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "#lfw_people=fetch_lfw_people(min_faces_per_person=10,color=True,slice_=(slice(61,189),slice(61,189)),resize=0.25)\n",
    "\n",
    "#x=lfw_people.images\n",
    "#y=lfw_people.target\n",
    "x=qq\n",
    "y=target\n",
    "\n",
    "#target_names=lfw_people.target_names\n",
    "#n_classes=target_names.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.05,shuffle=False)\n",
    "\n",
    "\n",
    "# #two people\n",
    "# X_train_two = []\n",
    "# y_train_two = []\n",
    "# X_test_two = []\n",
    "# y_test_two = []\n",
    "# for ct_d in range(X_train.shape[0]):\n",
    "#     if  y_train[ct_d] == 6:\n",
    "#         X_train_two.append(X_train[ct_d])\n",
    "#         y_train_two.append(0)\n",
    "#     if  y_train[ct_d] == 9:\n",
    "#         X_train_two.append(X_train[ct_d])\n",
    "#         y_train_two.append(1)\n",
    "        \n",
    "# for ct_d in range(X_test.shape[0]):\n",
    "#     if  y_train[ct_d] == 6:        \n",
    "#         X_test_two.append(X_test[ct_d])\n",
    "#         y_test_two.append(0)\n",
    "#     if  y_train[ct_d] == 9:\n",
    "#         X_test_two.append(X_test[ct_d])\n",
    "#         y_test_two.append(1)\n",
    "        \n",
    "# X_train = np.asarray(X_train_two)    \n",
    "# X_test = np.asarray(X_test_two)  \n",
    "# y_train = np.asarray(y_train_two)  \n",
    "# y_test = np.asarray(y_test_two)  \n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "         \n",
    "#X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "#X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "#X_train = torch.transpose\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_train /= 255.0\n",
    "#X_test /= 255.0\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "x_train = torch.Tensor(X_train).to(device)\n",
    "x_train = x_train.transpose(2,3).transpose(1,2)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "x_test = torch.FloatTensor(X_test).to(device)\n",
    "x_test = x_test.transpose(2,3).transpose(1,2)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "\n",
    "training = data.TensorDataset(x_train,y_train)\n",
    "\n",
    "testing = data.TensorDataset(x_test,y_test)\n",
    "\n",
    "dst_tensor=training\n",
    "\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "optimizer_train = optim.Adam(net.parameters(),lr=0.01)#,momentum=0.9)\n",
    "trainloader = torch.utils.data.DataLoader(training,batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46S2C4-1Xaa-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D5lscCERel6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSqlKEZ4W6P3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1680819116789,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "5-MQuEoEB823",
    "outputId": "198926b0-8262-416f-b8fa-8d954be495de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_ = 0\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    for i,data in enumerate(trainloader):\n",
    "   \n",
    "        #if epoch>=1:\n",
    "        if i==1:\n",
    "            #break\n",
    "            iter_=iter_+1\n",
    "            #print (iter_)\n",
    "            inputs,label = data\n",
    "            #print(input.size())    #printed previously for me.\n",
    "\n",
    "            inputs,label =  Variable(inputs),Variable(label) \n",
    "\n",
    "            optimizer_train.zero_grad()\n",
    "\n",
    "\n",
    "            outputs_benign=net(inputs)\n",
    "            \n",
    "            #outputs_benign = F.softmax(outputs_benign, dim=-1)\n",
    "            #print (outputs_benign[0])\n",
    "\n",
    "\n",
    "            loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "            #print(\"loss computed\")\n",
    "            loss_benign.backward()\n",
    "            #print(\"loss BP\")\n",
    "            optimizer_train.step()\n",
    "\n",
    "            #if i%2000==0:\n",
    "            print (loss_benign.item())\n",
    "            #torch.save(net.state_dict(),'./LFW_net.pth')  \n",
    "       \n",
    "  \n",
    "print ('fininshed training')\n",
    "total = len(y_test)\n",
    "acc =0.0\n",
    "for ct in range(total):\n",
    "    testing_data = tt(testing[ct][0].cpu())\n",
    "    testing_data1 = tp(testing_data).to(device)\n",
    "    testing_data2 = testing_data1.view(1, *testing_data1.size())\n",
    "    #print(testing_data2.size())\n",
    "    y_pred = net(testing_data2)\n",
    "    predicted = torch.argmax(y_pred)\n",
    "    #print(predicted, y_test[ct])\n",
    "    if predicted == y_test[ct]:\n",
    "        acc=acc+1\n",
    "        #print(acc)\n",
    "accuracy = acc / total\n",
    "print (accuracy)\n",
    "print ('fininshed testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1680819225092,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "s6nglmIJBrlc",
    "outputId": "e007a3f5-bff5-4534-bebd-58f051593774"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4895,
     "status": "ok",
     "timestamp": 1680819400218,
     "user": {
      "displayName": "Badhan Chandra Das",
      "userId": "15076996433094840570"
     },
     "user_tz": 240
    },
    "id": "ojDb4FWcEJeR",
    "outputId": "988ae655-f167-45f9-b1cb-b1538be8fb32"
   },
   "outputs": [],
   "source": [
    "pip install pytorch-msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3cPqOpNOTDR"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst_tensor_new=training+testing\n",
    "# len(dst_tensor_new)\n",
    "len(dst_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# generate dummy data and label\n",
    "mse_final=[]\n",
    "AS=0\n",
    "sSim_final=[]\n",
    "whole_duration=0\n",
    "loss_value=0\n",
    "count=0\n",
    "ASR=0\n",
    "for ii in range(0,len(dst_tensor),54):\n",
    "    print(\"Image ID and Image count: \",ii, count+1)\n",
    "    ######### honest partipant #########\n",
    "    img_index = ii #use img_index\n",
    "    dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index\n",
    "\n",
    "    gt_data = tp(dst_pil).to(device)\n",
    "    gt_data = torch.unsqueeze(gt_data,0)\n",
    "\n",
    "    gt_label = dst_tensor[img_index][1].long().to(device) #use img_index\n",
    "    gt_label = gt_label.view(1, )\n",
    "    gt_onehot_label = label_to_onehot(gt_label, num_classes=4)\n",
    "\n",
    "    plt.imshow(dst_pil)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    batch =1  #\n",
    "    for bat in range(batch-1):\n",
    "        dst_pil = tt(dst_tensor[img_index+1+bat][0].cpu())   #use img_index\n",
    "        tmp = torch.unsqueeze(tp(dst_pil).to(device),0)\n",
    "        #print(tmp.shape)\n",
    "        gt_data = torch.cat((gt_data,tmp),0)\n",
    "\n",
    "        gt_label_tmp = dst_tensor[img_index+1+bat][1].long().to(device) #use img_index\n",
    "        gt_label_tmp = gt_label_tmp.view(1, )\n",
    "        gt_label = torch.cat((gt_label,gt_label_tmp),0)\n",
    "        gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=4)),0)\n",
    "\n",
    "        if gt_label_tmp ==60:\n",
    "            print (bat)\n",
    "\n",
    "        plt.imshow(dst_pil)\n",
    "        #plt.savefig(\"./original/index_%s_label_%s\"%(bat+1,gt_label_tmp.item()))\n",
    "\n",
    "        #plt.title(\"Ground truth image\")\n",
    "        #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "\n",
    "    gt_label = torch.reshape(gt_label,(-1,1))    \n",
    "    print (gt_data.shape)\n",
    "    print (gt_label.shape)\n",
    "    print (gt_label)\n",
    "    print (gt_onehot_label.shape)\n",
    "\n",
    "    plt.imshow(tt(gt_data[0].cpu()),cmap='gray')\n",
    "    #plt.imshow(invTrans(dst_tensor[66][0].cpu()).permute(1, 2, 0))\n",
    "    # plt.axis('off')\n",
    "    # plt.savefig(\"./attack_image/tifs\")\n",
    "\n",
    "\n",
    "    # compute original gradient \n",
    "    dy_dx = []\n",
    "    original_dy_dx=[]\n",
    "    original_pred = []\n",
    "    for item in range(batch):\n",
    "        gt_data_single = torch.unsqueeze(gt_data[item],0)\n",
    "        out = net(gt_data_single)\n",
    "        #y = criterion(out, gt_onehot_label[item])\n",
    "        y = criterion(out, gt_label[item])\n",
    "        dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)\n",
    "        original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))\n",
    "        original_dy_dx.append(original_dy_dx_tmp)\n",
    "        out_tmp = out.detach().clone()\n",
    "        original_pred.append(out_tmp)\n",
    "\n",
    "\n",
    "        #dy_dx.append(torch.autograd.grad(y, net.parameters()))\n",
    "\n",
    "\n",
    "\n",
    "    # #FOR fully-connected model only\n",
    "    #     dw = net.body[0].weight\n",
    "    #     db = net.body[0].bias\n",
    "    #     dy_dw = torch.autograd.grad(y, dw,retain_graph=True)\n",
    "    #     dy_db = torch.autograd.grad(y, db,retain_graph=True)\n",
    "\n",
    "    #     print (dy_dw)\n",
    "    #     #print (dy_db.shape)\n",
    "\n",
    "    #     leak=dy_dw/dy_db\n",
    "\n",
    "    #     print (leak.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # share the gradients with other clients\n",
    "    #original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "\n",
    "    import time\n",
    "\n",
    "    from pytorch_msssim import ssim\n",
    "    from skimage import measure\n",
    "\n",
    "\n",
    "    #print (ssim(0.43*torch.unsqueeze(gt_data[0],dim=0),torch.unsqueeze(gt_data[0],dim=0),data_range=0).item())\n",
    "    #print (torch.dist(0.6*torch.unsqueeze(gt_data[0],dim=0),torch.unsqueeze(gt_data[0],dim=0),2).item())\n",
    "\n",
    "\n",
    "    for item in range(1):\n",
    "        start = time.process_time()\n",
    "        for rd in range(1):\n",
    "\n",
    "            #torch.manual_seed(200*rd)\n",
    "            #dummy_data = torch.unsqueeze(torch.randn(gt_data[item].size()),0).to(device).requires_grad_(True)\n",
    "\n",
    "            #dummy_data = torch.unsqueeze(torch.zeros(gt_data[item].size()),0).to(device).requires_grad_(True)\n",
    "            #dummy_data = torch.unsqueeze(torch.ones(gt_data[item].size()),0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "            #background = torch.unsqueeze(torch.zeros(gt_data[item].size()),0)\n",
    "            #background[0,0,::] = 1\n",
    "            #dummy_data = background.to(device).requires_grad_(True)\n",
    "            ##dummy_data = (torch.unsqueeze(torch.randn(gt_data[item].size()),0)+background).to(device).requires_grad_(True)\n",
    "\n",
    "            #surrogate = torch.unsqueeze(gt_data[item+1],0)\n",
    "            #aaa = torch.rand([3,16,16])\n",
    "            #surrogate[0,:,8:24,8:24] =aaa\n",
    "            #dummy_data = surrogate.to(device).requires_grad_(True)    \n",
    "\n",
    "            #dummy_data = torch.unsqueeze(gt_data[item+1],0).to(device).requires_grad_(True)\n",
    "\n",
    "            #k = np.random.randint(0,95)\n",
    "            #dummy_data = torch.unsqueeze(gt_data[k],0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "            pat_1 = torch.rand([3,16,16])\n",
    "            pat_2 = torch.cat((pat_1,pat_1),dim=1)\n",
    "            pat_4 = torch.cat((pat_2,pat_2),dim=2)\n",
    "            dummy_data = torch.unsqueeze(pat_4,dim=0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "            #aaa = torch.rand([3,8,8])\n",
    "            #bbb = torch.cat((aaa,aaa),dim=1)\n",
    "            #ccc = torch.cat((bbb,bbb),dim=1)\n",
    "            #ddd = torch.cat((ccc,ccc),dim=2)\n",
    "            #eee = torch.cat((ddd,ddd),dim=2)\n",
    "            #dummy_data = torch.unsqueeze(eee,dim=0).to(device).requires_grad_(True)\n",
    "\n",
    "            #aaa = torch.rand([3,4,4])\n",
    "            #bbb = torch.cat((aaa,aaa),dim=1)\n",
    "            #ccc = torch.cat((bbb,bbb),dim=1)\n",
    "            #ddd = torch.cat((ccc,ccc),dim=1)\n",
    "            #eee = torch.cat((ddd,ddd),dim=2)\n",
    "            #fff = torch.cat((eee,eee),dim=2)\n",
    "            #ggg = torch.cat((fff,fff),dim=2)\n",
    "            #dummy_data = torch.unsqueeze(ggg,dim=0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "            #dummy_data = plt.imread(\"./attack_image/replacement_69.png\")\n",
    "            #print (dummy_data.shape)\n",
    "            #dummy_data = torch.FloatTensor(dummy_data).to(device)\n",
    "            #dummy_data = dummy_data.transpose(2,3).transpose(1,2)\n",
    "\n",
    "            dummy_unsqueeze=torch.unsqueeze(gt_onehot_label[item],dim=0)\n",
    "\n",
    "            dummy_label = torch.randn(dummy_unsqueeze.size()).to(device).requires_grad_(True)\n",
    "            label_pred=torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), \n",
    "                                    dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "            #print (original_dy_dx[item][-1].shape)\n",
    "            #print (original_dy_dx[item][-1].argmin())\n",
    "\n",
    "            #print (torch.sum(original_dy_dx[item][-2], dim=-1).argmin())\n",
    "\n",
    "            plt.imshow(tt(dummy_data[0]))\n",
    "            #plt.title(\"Dummy data\")\n",
    "            #plt.savefig(\"./random_seed/index_%s_rand_seed_%s_label_%s\"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))\n",
    "\n",
    "            #plt.clf()\n",
    "            print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "            print(\"stolen label is %d.\" % label_pred.item())\n",
    "\n",
    "\n",
    "            #optimizer = torch.optim.LBFGS([dummy_data,dummy_label])\n",
    "            optimizer = torch.optim.LBFGS([dummy_data,])\n",
    "            #optimizer = torch.optim.AdamW([dummy_data,],lr=0.01)\n",
    "            #optimizer = torch.optim.SGD([dummy_data,],lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "            history = []\n",
    "\n",
    "            percept_dis = np.zeros(300)\n",
    "            recover_dis = np.zeros(300)\n",
    "            for iters in range(300):\n",
    "\n",
    "\n",
    "                percept_dis[iters]=ssim(dummy_data,torch.unsqueeze(gt_data[item],dim=0),data_range=0).item()\n",
    "                #recover_dis[iters]=torch.dist(dummy_data,torch.unsqueeze(gt_data[item],dim=0),2).item()\n",
    "                recover_dis[iters]= F.mse_loss(dummy_data,torch.unsqueeze(gt_data[item],dim=0),  reduction='mean').item()\n",
    "\n",
    "                history.append(tt(dummy_data[0].cpu()))\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    pred = net(dummy_data) \n",
    "\n",
    "                    #dummy_onehot_label = F.softmax(dummy_label, dim=-1).long()\n",
    "\n",
    "                    #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "                    ##print (pred)\n",
    "                    ##print (label_pred)\n",
    "\n",
    "                    dummy_loss = criterion(pred, label_pred)\n",
    "                    dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "                    ##dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)\n",
    "                    ##print (dummy_dy_dp[0].shape)  \n",
    "\n",
    "                    grad_diff = 0\n",
    "                    grad_count = 0\n",
    "                    #count =0\n",
    "                    #print(type(dummy_dy_dx))\n",
    "                    dummy_dy_dx=list(dummy_dy_dx)\n",
    "                    #print(type(original_dy_dx[item]))\n",
    "                    for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here\n",
    "\n",
    "                        #if iters==500 or iters== 1200:\n",
    "                        #print (gx[0])\n",
    "                        #    print ('hahaha')\n",
    "                        #print (gy[0])\n",
    "                        lasso = torch.norm(dummy_data,p=1)\n",
    "                        ridge = torch.norm(dummy_data,p=2)\n",
    "                        grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge \n",
    "\n",
    "                        #print (gx.shape)\n",
    "\n",
    "                        grad_count += gx.nelement()\n",
    "\n",
    "\n",
    "                        #if count == 9:\n",
    "                        #    break\n",
    "                        #count=count+1\n",
    "                    # grad_diff = grad_diff / grad_count * 1000\n",
    "\n",
    "                    #grad_diff += ((original_pred[item]-pred)**2).sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    grad_diff.backward()\n",
    "                    #print (count)\n",
    "\n",
    "                    #print (dummy_dy_dx)\n",
    "                    #print (original_dy_dx)\n",
    "\n",
    "\n",
    "                    return grad_diff\n",
    "\n",
    "\n",
    "\n",
    "                optimizer.step(closure)\n",
    "                if iters % 5 == 0: \n",
    "                    current_loss = closure()\n",
    "                    #if iters == 0: \n",
    "                    #print (\"%.8f\" % current_loss.item())\n",
    "                    #print(iters, \"%.8f\" % current_loss.item())\n",
    "                history.append(tt(dummy_data[0].cpu()))\n",
    "\n",
    "\n",
    "\n",
    "            #plt.figure(figsize=(18, 12))\n",
    "            #for i in range(60):\n",
    "            #  plt.subplot(6, 10, i + 1)\n",
    "            #  plt.imshow(history[i * 5])\n",
    "            #  plt.title(\"iter=%d\" % (i * 5))\n",
    "            #  plt.axis('off')\n",
    "\n",
    "            #plt.figure(figsize=(12, 1.5))\n",
    "            #iter_idx = [0,20,40,60,80,100,120,140,160,180]\n",
    "            #plt.figure(figsize=(6.5, 1.2))\n",
    "            #iter_idx = [0,1000,2000,3000,4000,5000]\n",
    "            iter_idx = [0,5,10,20,50,100]\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            #np.savetxt('ssim_random2',percept_dis,fmt=\"%4f\")\n",
    "            #np.savetxt('mse_random2',recover_dis,fmt=\"%4f\")\n",
    "\n",
    "            #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "            #plt.savefig(\"./attack_image/index_%s_rand_%s_label_%s\"%(item,rd, label_pred.item()))\n",
    "            #plt.clf()\n",
    "\n",
    "        duration = time.process_time()-start\n",
    "    \n",
    "        print (\"Running time is %.4f.\" %(duration) )\n",
    "        print (\"Duration = \",duration/10.0)\n",
    "        print(\"ssim_random2\", percept_dis)\n",
    "        print(\"mse_random2\", recover_dis)\n",
    "    count=count+1\n",
    "    sSim_final.append(percept_dis[299])\n",
    "    mse_final.append(recover_dis[299])\n",
    "    whole_duration=whole_duration+(duration)\n",
    "    if(percept_dis[299]>=.90):\n",
    "        AS=AS+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sSim_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count)\n",
    "ASR=AS/count\n",
    "print(\"Attack Success Rate: \", ASR)\n",
    "print(\"Avg. SSIM: \", np.mean(sSim_final))\n",
    "print(\"Avg. MSE: \", np.mean(mse_final))\n",
    "print(\"Avg. Duration:\", whole_duration/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "  plt.subplot(1, 6, i + 1)\n",
    "  plt.imshow(history[iter_idx[i]])\n",
    "  plt.title(\"iter=%d\" % (iter_idx[i]))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "GPU_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
