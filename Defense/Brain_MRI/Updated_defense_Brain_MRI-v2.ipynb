{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda create --name new-env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install python=3.8.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91749a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision torchaudio cudatoolkit=12 -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda); \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1caf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn.functional as func\n",
    "#torch.manual_seed(50)\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)\n",
    "print (torch.cuda.get_device_name(device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1686f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from zipfile import ZipFile\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b92d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='Brain-Tumor-MRI-Dataset'\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/Testing\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e887bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125db782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((32,32)),\n",
    "     #transforms.RandomCrop(32),\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "     #transforms.ConvertImageDtype(torch.float)\n",
    "     ])\n",
    "\n",
    "dataset = ImageFolder(data_dir+'/Testing', transform=transform)\n",
    "#dataset1 = DataLoader(trainset, shuffle=True, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c027f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data=[]\n",
    "target=[]\n",
    "for i, j in dataset:\n",
    "  image_data.append(i)\n",
    "  target.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72247a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data1=torch.stack(image_data)\n",
    "image_data2=image_data1.numpy()\n",
    "image_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d893f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq=np.rollaxis(image_data2,1,4)\n",
    "qq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959de79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
    "# dst = datasets.MNIST(\"~/.torch\", download=True)\n",
    "\n",
    "tp = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tt = transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "print(\"Running on %s\" % device)\n",
    "\n",
    "def label_to_onehot(target, num_classes=4):\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "    onehot_target.scatter_(1, target, 1)\n",
    "    return onehot_target\n",
    "\n",
    "def cross_entropy_for_onehot(pred, target):\n",
    "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00019c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.5, 0.5)\n",
    "#         nn.init.xavier_uniform_(m.weight.data)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         #m.bias.data.uniform_(-0.5, 0.5)\n",
    "#         #nn.init.xavier_uniform(m.bias.data)\n",
    "#         m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "\n",
    "# class LeNet(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "\n",
    "#         super(LeNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, kernel_size=5,stride=2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=2)\n",
    "#         self.fc1 = nn.Linear(16*5*5, 256)\n",
    "#         self.fc2 = nn.Linear(256, 120)\n",
    "#         self.fc3 = nn.Linear(120, 106)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         #x = func.relu(self.conv1(x))\n",
    "#         x = func.sigmoid(self.conv1(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         #x = func.relu(self.conv2(x))\n",
    "#         x = func.sigmoid(self.conv2(x))\n",
    "#         #x = func.max_pool2d(x, 2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         #x = func.relu(self.fc1(x))\n",
    "#         x = func.sigmoid(self.fc1(x))\n",
    "#         #x = func.relu(self.fc2(x))\n",
    "#         x = func.sigmoid(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "    \n",
    "    \n",
    "# def weights_init(m):\n",
    "#     if hasattr(m, \"weight\"):\n",
    "#         m.weight.data.uniform_(-0.3, 0.3)\n",
    "#     if hasattr(m, \"bias\"):\n",
    "#         m.bias.data.uniform_(-0.3, 0.3)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if hasattr(m, \"weight\"):\n",
    "        m.weight.data.uniform_(-0.5, 0.5)\n",
    "    if hasattr(m, \"bias\"):\n",
    "        m.bias.data.uniform_(-0.5, 0.5)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        #act = nn.ReLU\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = LeNet().to(device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "#criterion = cross_entropy_for_onehot\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "#lfw_people=fetch_lfw_people(min_faces_per_person=14,color=True,slice_=(slice(61,189),slice(61,189)),resize=0.25) #14\n",
    "#x=lfw_people.images\n",
    "#y=lfw_people.target\n",
    "x=qq\n",
    "y=target\n",
    "\n",
    "#target_names=lfw_people.target_names\n",
    "n_classes=4\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (n_classes)\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20455bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "#X_train = torch.transpose\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_train /= 255.0\n",
    "#X_test /= 255.0\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "x_train = torch.FloatTensor(X_train).to(device)\n",
    "x_train = x_train.transpose(2,3).transpose(1,2)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "\n",
    "x_test = torch.FloatTensor(X_test).to(device)\n",
    "x_test = x_test.transpose(2,3).transpose(1,2)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "\n",
    "training = data.TensorDataset(x_train,y_train)\n",
    "\n",
    "testing = data.TensorDataset(x_test,y_test)\n",
    "\n",
    "dst_tensor=training\n",
    "\n",
    "criterion_train = nn.CrossEntropyLoss()\n",
    "optimizer_train = optim.Adam(net.parameters(),lr=0.01)#,momentum=0.9)\n",
    "trainloader = torch.utils.data.DataLoader(training, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(0):\n",
    "\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "    #for data in trainloader:\n",
    "        #if i<=10: \n",
    "\n",
    "            inputs,label = data\n",
    "\n",
    "            inputs,label =  Variable(inputs).to(device),Variable(label).to(device)\n",
    "\n",
    "            optimizer_train.zero_grad()\n",
    "            outputs_benign=net(inputs)\n",
    "\n",
    "            loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "            loss_benign.backward()\n",
    "            #sgd_update(net.parameters())\n",
    "\n",
    "            optimizer_train.step()\n",
    "            \n",
    "            testloader = torch.utils.data.DataLoader(testing,batch_size=test_size, shuffle=False)\n",
    "\n",
    "            acc =0.0\n",
    "            for ji,tdata in enumerate(testloader,0):\n",
    "\n",
    "                tinputs,tlabel = tdata\n",
    "\n",
    "                tinputs,tlabel =  Variable(tinputs).to(device),Variable(tlabel).to(device)\n",
    "\n",
    "                toutputs=net(tinputs)\n",
    "\n",
    "                tpredict = torch.argmax(toutputs, dim=1)\n",
    "\n",
    "\n",
    "                for mi in range(test_size):\n",
    "\n",
    "\n",
    "\n",
    "                    if tpredict[mi] == tlabel[mi]:\n",
    "                        acc=acc+1\n",
    "\n",
    "            accuracy = acc / test_size\n",
    "            print (accuracy)\n",
    "            print ('fininshed testing')\n",
    "            if accuracy>0.18:\n",
    "                break\n",
    "\n",
    "\n",
    "print ('fininshed training')\n",
    "#torch.save(net.state_dict()\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testing,batch_size=test_size, shuffle=False)\n",
    "\n",
    "acc =0.0\n",
    "for ji,tdata in enumerate(testloader,0):\n",
    "\n",
    "    tinputs,tlabel = tdata\n",
    "\n",
    "    tinputs,tlabel =  Variable(tinputs).to(device),Variable(tlabel).to(device)\n",
    "\n",
    "    toutputs=net(tinputs)\n",
    "    \n",
    "    tpredict = torch.argmax(toutputs, dim=1)\n",
    "    \n",
    "   \n",
    "    for mi in range(test_size):\n",
    "        \n",
    "        \n",
    "\n",
    "        if tpredict[mi] == tlabel[mi]:\n",
    "            acc=acc+1\n",
    "\n",
    "accuracy = acc / test_size\n",
    "print (accuracy)\n",
    "print ('fininshed testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[855], alpha =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4327dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch-msssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e529e7",
   "metadata": {},
   "source": [
    "# Noise Level 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dec2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ssim\n",
    "\n",
    "#dgc_rate_list = [20,30,40,50,70, 80,90]\n",
    "\n",
    "#for epoch in range(1):\n",
    "#for dgc_rate in dgc_rate_list:\n",
    "gau_rate_list = [100]\n",
    "for gau_rate in gau_rate_list:\n",
    "\n",
    "    \n",
    "    print('now starting',gau_rate)\n",
    "\n",
    "    for iter_,data in enumerate(trainloader,1):\n",
    "        \n",
    "        if iter_ != 1:\n",
    "            break\n",
    "   \n",
    "        ######### honest partipant #########\n",
    "        img_index = 855   #use img_index\n",
    "        dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index\n",
    "\n",
    "        gt_data = transform(dst_pil).to(device)\n",
    "        gt_data = torch.unsqueeze(gt_data,0)\n",
    "\n",
    "        gt_label = dst_tensor[img_index][1].long().to(device) #use img_index\n",
    "        gt_label = gt_label.view(1, )\n",
    "        gt_onehot_label = label_to_onehot(gt_label, num_classes=4)\n",
    "\n",
    "        plt.imshow(dst_pil)\n",
    "        plt.axis('off')\n",
    "        #plt.savefig(\"/content/sample_data\")\n",
    "\n",
    "\n",
    "\n",
    "        batch =2  #\n",
    "        for bat in range(batch-1):\n",
    "            dst_pil = tt(dst_tensor[img_index+1+bat][0].cpu())   #use img_index\n",
    "            tmp = torch.unsqueeze(transform(dst_pil).to(device),0)\n",
    "            #print(tmp.shape)\n",
    "            gt_data = torch.cat((gt_data,tmp),0)\n",
    "\n",
    "            gt_label_tmp = dst_tensor[img_index+1+bat][1].long().to(device) #use img_index\n",
    "            gt_label_tmp = gt_label_tmp.view(1, )\n",
    "            gt_label = torch.cat((gt_label,gt_label_tmp),0)\n",
    "            gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=4)),0)\n",
    "\n",
    "            plt.imshow(dst_pil)\n",
    "            #plt.savefig(\"./original/index_%s_label_%s\"%(bat+1,gt_label_tmp.item()))\n",
    "\n",
    "            #plt.title(\"Ground truth image\")\n",
    "            #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "\n",
    "        gt_label = torch.reshape(gt_label,(-1,1))    \n",
    "        #print (gt_data.shape)\n",
    "        #print (gt_label.shape)\n",
    "        #print (gt_onehot_label.shape)\n",
    "\n",
    "\n",
    "        # compute original gradient \n",
    "        dy_dx = []\n",
    "        original_dy_dx=[]\n",
    "        original_pred = []\n",
    "        for item in range(batch):\n",
    "            gt_data_single = torch.unsqueeze(gt_data[item],0)\n",
    "            out = net(gt_data_single)\n",
    "            #y = criterion(out, gt_onehot_label[item])\n",
    "            y = criterion(out, gt_label[item])\n",
    "            dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)\n",
    "            original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))\n",
    "            original_dy_dx.append(original_dy_dx_tmp)\n",
    "            out_tmp = out.detach().clone()\n",
    "            original_pred.append(out_tmp)\n",
    "            \n",
    "            \n",
    "        #if gaussian noise or laplace\n",
    "        m = torch.distributions.laplace.Laplace(torch.tensor([0.0]), torch.tensor([1/gau_rate]))\n",
    "        for item in range(batch):\n",
    "            for layer_idx in range(10):\n",
    "                #original_dy_dx[item][layer_idx] =  original_dy_dx[item][layer_idx] + torch.empty(original_dy_dx[item][layer_idx].size()).normal_(mean=0,std=1/gau_rate).to(device)\n",
    "                original_dy_dx[item][layer_idx] =  original_dy_dx[item][layer_idx] + torch.squeeze(m.sample(sample_shape=original_dy_dx[item][layer_idx].size()),dim=-1).to(device)\n",
    "                #break\n",
    "        ##if deep gradient compression\n",
    "        #print (original_dy_dx[0][0][0])\n",
    "        #for item in range(batch):\n",
    "        #    for layer_idx in range(10):\n",
    "        #        if layer_idx == 0:    \n",
    "        #            flat_dy_dx = torch.flatten(original_dy_dx[item][layer_idx])\n",
    "        #        else:\n",
    "        #            flat_dy_dx = torch.cat((flat_dy_dx,torch.flatten(original_dy_dx[item][layer_idx])),0)\n",
    "        #sorted_dy_dx = flat_dy_dx.abs().sort()\n",
    "        #size = np.asarray(list(flat_dy_dx.shape))\n",
    "        #thresh = sorted_dy_dx[0][int(size * dgc_rate/100.0)]\n",
    "        #print (size)\n",
    "        #print (int(size * dgc_rate/100.0))\n",
    "        #print (thresh)\n",
    "        #print (sorted_dy_dx[0][-1])\n",
    "        #for item in range(batch):\n",
    "        #    for layer_idx in range(10):\n",
    "        #        shape_tmp = original_dy_dx[item][layer_idx].size()\n",
    "        #        flat_dy_dx_prune = torch.flatten(original_dy_dx[item][layer_idx])\n",
    "        #        size_tmp = np.asarray(list(flat_dy_dx_prune.shape))\n",
    "        #        for m in range(int(size_tmp)):\n",
    "        #            if flat_dy_dx_prune[m].abs()<=thresh:\n",
    "        #                flat_dy_dx_prune[m] = 0\n",
    "        #        original_dy_dx[item][layer_idx] = flat_dy_dx_prune.view(shape_tmp)\n",
    "        #print (original_dy_dx[0][0][0])\n",
    "              \n",
    "\n",
    "        # generate dummy data and label\n",
    "        import time\n",
    "\n",
    "        #if iter_ % 10 ==0: \n",
    "        if iter_ == 1:\n",
    "            \n",
    "            #print ('epoch',epoch,'iter',iter_)\n",
    "            for item in range(1):\n",
    "                start = time.process_time()\n",
    "                for rd in range(1):\n",
    "\n",
    "                    torch.manual_seed(100*rd)\n",
    "\n",
    "                    pat_1 = torch.rand([3,16,16])\n",
    "                    pat_2 = torch.cat((pat_1,pat_1),dim=1)\n",
    "                    pat_4 = torch.cat((pat_2,pat_2),dim=2)\n",
    "                    dummy_data = torch.unsqueeze(pat_4,dim=0).to(device).requires_grad_(True)     \n",
    "\n",
    "                    dummy_unsqueeze=torch.unsqueeze(gt_onehot_label[item],dim=0)\n",
    "\n",
    "                    dummy_label = torch.randn(gt_onehot_label[item].size()).to(device).requires_grad_(True)\n",
    "                    label_pred = torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "                    label_pred_onehot = label_to_onehot(label_pred, num_classes=4)\n",
    "\n",
    "                    plt.imshow(tt(dummy_data[0].cpu()))\n",
    "                    plt.title(\"Dummy data\")\n",
    "                    #plt.savefig(\"./random_seed/index_%s_rand_seed_%s_label_%s\"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))\n",
    "\n",
    "                    plt.clf()\n",
    "                    #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "                    #print(\"stolen label is %d.\" % label_pred.item())\n",
    "\n",
    "                    #optimizer = torch.optim.LBFGS([dummy_data,dummy_label])\n",
    "                    optimizer = torch.optim.LBFGS([dummy_data,])\n",
    "\n",
    "\n",
    "                    history = []\n",
    "                    history_batch = []\n",
    "                    history_grad = []\n",
    "\n",
    "                    percept_dis = np.zeros(100)\n",
    "                    recover_dis = np.zeros(100)\n",
    "                    for iters in range(100):\n",
    "\n",
    "                        percept_dis[iters]=ssim(dummy_data,torch.unsqueeze(gt_data[item],dim=0),data_range=0).item()\n",
    "                        #recover_dis[iters]=torch.dist(dummy_data,torch.unsqueeze(gt_data[item],dim=0),2).item()\n",
    "                        recover_dis[iters]= F.mse_loss(dummy_data,torch.unsqueeze(gt_data[item],dim=0)).item()\n",
    "\n",
    "                        history.append(tt(dummy_data[0].cpu()))\n",
    "\n",
    "                        def closure():\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            pred = net(dummy_data) \n",
    "                            dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
    "                            #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "\n",
    "                            #dummy_loss = criterion(pred, label_pred_onehot)\n",
    "                            dummy_loss = criterion(pred, label_pred)\n",
    "\n",
    "\n",
    "                            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "                            #dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)\n",
    "                            #print (dummy_dy_dp[0].shape)\n",
    "\n",
    "                            grad_diff = 0\n",
    "                            grad_count = 0\n",
    "                            #count =0\n",
    "                            for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here\n",
    "\n",
    "                                #if iters==500 or iters== 1200:\n",
    "                                #    print (gx[0])\n",
    "                                #    print ('hahaha')\n",
    "                                #    print (gy[0])\n",
    "                                lasso = torch.norm(dummy_data,p=1)\n",
    "                                ridge = torch.norm(dummy_data,p=2)\n",
    "                                grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge\n",
    "\n",
    "\n",
    "                                grad_count += gx.nelement()\n",
    "\n",
    "                                #if count == 9:\n",
    "                                #    break\n",
    "                                #count=count+1\n",
    "                            # grad_diff = grad_diff / grad_count * 1000\n",
    "                            grad_diff.backward()\n",
    "                            #print (count)\n",
    "\n",
    "                            #print (dummy_dy_dx)\n",
    "                            #print (original_dy_dx)\n",
    "\n",
    "\n",
    "                            return grad_diff\n",
    "\n",
    "\n",
    "\n",
    "                        optimizer.step(closure)\n",
    "                        if iters % 5 == 0: \n",
    "                            current_loss = closure()\n",
    "                            #if iters == 0: \n",
    "                            #print (\"%.8f\" % current_loss.item())\n",
    "                            #print(iters, \"%.8f\" % current_loss.item())\n",
    "\n",
    "                    #     for bat in range(batch-1):\n",
    "                    #         history_batch.append(tt(dummy_data[bat].cpu()))\n",
    "\n",
    "                    #plt.figure(figsize=(30, 20))\n",
    "                    #for i in range(100):\n",
    "                    #    plt.subplot(10, 10, i + 1)\n",
    "                    #    plt.imshow(history[i * 5])\n",
    "                    #    plt.title(\"iter=%d\" % (i * 5))\n",
    "                    #    plt.axis('off')\n",
    "                    #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "\n",
    "                    #np.savetxt('./attack_image/lfw_ssim_idx_%s_laplace_%s'%(item,gau_rate),percept_dis,fmt=\"%4f\")\n",
    "                    #np.savetxt('./attack_image/lfw_mse_idx_%s_laplace_%s'%(item,gau_rate),recover_dis,fmt=\"%4f\")\n",
    "                    #plt.savefig(\"./attack_image/lfw_index_%s_laplace_%s\"%(item,gau_rate))\n",
    "\n",
    "                    #plt.clf()\n",
    "                    \n",
    "                    pinp = np.argmin(recover_dis)\n",
    "                    plt.imshow(history[pinp])\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    #plt.figure(figsize=(15, 10))\n",
    "                    #for i in range(60):\n",
    "                    #    plt.subplot(6, 10, i + 1)\n",
    "                    #    plt.imshow(history[i * 14 ], cmap='gray')\n",
    "                    #    plt.title(\"iter=%d\" % (i*14))\n",
    "                    #    plt.axis('off')\n",
    "                    #plt.savefig(\"/content/sample_data\"%(item,gau_rate))\n",
    "                    \n",
    "                #duration = time.clock()-start\n",
    "                #print (\"Running time is %.4f.\" %(duration/10.0) )\n",
    "                #print (duration)\n",
    "                \n",
    "        \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "################################################### training when set to epoch\n",
    "\n",
    "#         #if epoch>=1:\n",
    "#         #if i==1:\n",
    "#             #break\n",
    "#         #print (iter_)\n",
    "#         inputs,label = data\n",
    "\n",
    "#         inputs,label =  Variable(inputs).to(device),Variable(label).to(device)\n",
    "\n",
    "#         optimizer_train.zero_grad()\n",
    "\n",
    "\n",
    "#         outputs_benign=net(inputs)\n",
    "#         #outputs_benign = F.softmax(outputs_benign, dim=-1)\n",
    "#         #print (outputs_benign[0])\n",
    "\n",
    "\n",
    "#         loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "#         #print(\"loss computed\")\n",
    "#         loss_benign.backward()\n",
    "#         #print(\"loss BP\")\n",
    "#         optimizer_train.step()\n",
    "#         #sgd_update(net.parameters())\n",
    "\n",
    "#         #if i%2000==0:\n",
    "#         #print (loss_benign.item())\n",
    "#         #torch.save(net.state_dict(),'./LFW_net.pth')  \n",
    "\n",
    "#         #if  iter_%50==0:\n",
    "#         #    print ('attack',iter_)\n",
    "       \n",
    "        \n",
    "#         print ('fininshed training')\n",
    "#         break\n",
    "###############################   testing\n",
    "    \n",
    "#         total = len(y_test)\n",
    "#         acc =0.0\n",
    "#         for ct in range(total):\n",
    "#             testing_data = tt(testing[ct][0].cpu())\n",
    "#             testing_data1 = tp(testing_data).to(device)\n",
    "#             testing_data2 = testing_data1.view(1, *testing_data1.size())\n",
    "#             y_pred = net(testing_data2)\n",
    "#             predicted = torch.argmax(y_pred)\n",
    "\n",
    "#             if predicted == y_test[ct]:\n",
    "#                 acc=acc+1\n",
    "#         accuracy = acc / total\n",
    "#         print (accuracy)\n",
    "#         print ('fininshed testing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb055b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ssim\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    for iter_,data in enumerate(trainloader,1):\n",
    "   \n",
    "        ######### honest partipant #########\n",
    "        img_index = 855  #use img_index\n",
    "        dst_pil = tt(dst_tensor[img_index][0].cpu())   #use img_index\n",
    "\n",
    "        gt_data = transform(dst_pil).to(device)\n",
    "        gt_data = torch.unsqueeze(gt_data,0)\n",
    "\n",
    "        gt_label = dst_tensor[img_index][1].long().to(device) #use img_index\n",
    "        gt_label = gt_label.view(1, )\n",
    "        gt_onehot_label = label_to_onehot(gt_label, num_classes=4)\n",
    "\n",
    "        plt.imshow(dst_pil)\n",
    "        #plt.savefig(\"./original/index_%s_label_%s\"%(img_index,gt_label.item()))\n",
    "\n",
    "\n",
    "\n",
    "        batch =32  #\n",
    "        for bat in range(batch-1):\n",
    "            dst_pil = tt(dst_tensor[img_index+1+bat][0].cpu())   #use img_index\n",
    "            tmp = torch.unsqueeze(transform(dst_pil).to(device),0)\n",
    "            #print(tmp.shape)\n",
    "            gt_data = torch.cat((gt_data,tmp),0)\n",
    "\n",
    "            gt_label_tmp = dst_tensor[img_index+1+bat][1].long().to(device) #use img_index\n",
    "            gt_label_tmp = gt_label_tmp.view(1, )\n",
    "            gt_label = torch.cat((gt_label,gt_label_tmp),0)\n",
    "            gt_onehot_label = torch.cat((gt_onehot_label,label_to_onehot(gt_label_tmp, num_classes=4)),0)\n",
    "\n",
    "            plt.imshow(dst_pil)\n",
    "            #plt.savefig(\"./original/index_%s_label_%s\"%(bat+1,gt_label_tmp.item()))\n",
    "\n",
    "            #plt.title(\"Ground truth image\")\n",
    "            #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "\n",
    "        gt_label = torch.reshape(gt_label,(-1,1))    \n",
    "        print (\"Image Shape = \",gt_data.shape)\n",
    "        print (\"Label shape = \",gt_label.shape)\n",
    "        print (\"Onehot Label shape = \",gt_onehot_label.shape)\n",
    "\n",
    "\n",
    "        # compute original gradient \n",
    "        dy_dx = []\n",
    "        original_dy_dx=[]\n",
    "        original_pred = []\n",
    "        for item in range(batch):\n",
    "            gt_data_single = torch.unsqueeze(gt_data[item],0)\n",
    "            out = net(gt_data_single)\n",
    "            #y = criterion(out, gt_onehot_label[item])\n",
    "            y = criterion(out, gt_label[item])\n",
    "            dy_dx = torch.autograd.grad(y, net.parameters(),retain_graph=True)\n",
    "            original_dy_dx_tmp = list((_.detach().clone() for _ in dy_dx))\n",
    "            original_dy_dx.append(original_dy_dx_tmp)\n",
    "            out_tmp = out.detach().clone()\n",
    "            original_pred.append(out_tmp)\n",
    "\n",
    "            #dy_dx.append(torch.autograd.grad(y, net.parameters()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # share the gradients with other clients\n",
    "        #original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "\n",
    "\n",
    "        # generate dummy data and label\n",
    "        import time\n",
    "\n",
    "\n",
    "        for item in range(1):\n",
    "            start = time.process_time()\n",
    "            for rd in range(1):\n",
    "\n",
    "                torch.manual_seed(100*rd)\n",
    "        \n",
    "                pat_1 = torch.rand([3,16,16])\n",
    "                pat_2 = torch.cat((pat_1,pat_1),dim=1)\n",
    "                pat_4 = torch.cat((pat_2,pat_2),dim=2)\n",
    "                dummy_data = torch.unsqueeze(pat_4,dim=0).to(device).requires_grad_(True)     \n",
    "\n",
    "                dummy_unsqueeze=torch.unsqueeze(gt_onehot_label[item],dim=0)\n",
    "\n",
    "                dummy_label = torch.randn(dummy_unsqueeze.size()).to(device).requires_grad_(True)\n",
    "                label_pred=torch.argmin(torch.sum(original_dy_dx[item][-2], dim=-1), \n",
    "                                        dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
    "                #print (original_dy_dx[item][-1].shape)\n",
    "                #print (original_dy_dx[item][-1].argmin())\n",
    "\n",
    "                #print (torch.sum(original_dy_dx[item][-2], dim=-1).argmin())\n",
    "\n",
    "                plt.imshow(tt(dummy_data[0].cpu()))\n",
    "                plt.title(\"Dummy data\")\n",
    "                #plt.savefig(\"./random_seed/index_%s_rand_seed_%s_label_%s\"%(item,rd,torch.argmax(dummy_label, dim=-1).item()))\n",
    "\n",
    "                plt.clf()\n",
    "                print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "                print(\"stolen label is %d.\" % label_pred.item())\n",
    "\n",
    "\n",
    "                #optimizer = torch.optim.LBFGS([dummy_data,dummy_label])\n",
    "                optimizer = torch.optim.LBFGS([dummy_data,])\n",
    "                #optimizer = torch.optim.AdamW([dummy_data,],lr=0.01)\n",
    "\n",
    "\n",
    "                history = []\n",
    "                history_batch = []\n",
    "                history_grad = []\n",
    "                \n",
    "                percept_dis = np.zeros(500)\n",
    "                recover_dis = np.zeros(500)\n",
    "                for iters in range(500):\n",
    "                    \n",
    "                    percept_dis[iters]=ssim(dummy_data,torch.unsqueeze(gt_data[item],dim=0),data_range=0).item()\n",
    "                    #recover_dis[iters]=torch.dist(dummy_data,torch.unsqueeze(gt_data[item],dim=0),2).item()\n",
    "                    recover_dis[iters]= F.mse_loss(dummy_data,torch.unsqueeze(gt_data[item],dim=0)).item()\n",
    "                    \n",
    "                    history.append(tt(dummy_data[0].cpu()))\n",
    "\n",
    "                    def closure():\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        pred = net(dummy_data) \n",
    "                        #dummy_onehot_label = F.softmax(dummy_label, dim=-1).long()\n",
    "\n",
    "                        #dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "                        #print (pred)\n",
    "                        #print (label_pred)\n",
    "\n",
    "                        dummy_loss = criterion(pred, label_pred)\n",
    "                        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "                        #dummy_dy_dp = torch.autograd.grad(dummy_loss, dummy_data, create_graph=True)\n",
    "                        #print (dummy_dy_dp[0].shape)  \n",
    "\n",
    "                        grad_diff = 0\n",
    "                        grad_count = 0\n",
    "                        #count =0\n",
    "                        for gx, gy in zip(dummy_dy_dx, original_dy_dx[item]): # TODO: fix the variablas here\n",
    "\n",
    "                            #if iters==500 or iters== 1200:\n",
    "                            #print (gx[0])\n",
    "                            #    print ('hahaha')\n",
    "                            #print (gy[0])\n",
    "                            lasso = torch.norm(dummy_data,p=1)\n",
    "                            ridge = torch.norm(dummy_data,p=2)\n",
    "                            grad_diff += ((gx - gy) ** 2).sum() #+ 0.0*lasso +0.01*ridge \n",
    "\n",
    "                            #print (gx.shape)\n",
    "\n",
    "                            grad_count += gx.nelement()\n",
    "\n",
    "\n",
    "                            #if count == 9:\n",
    "                            #    break\n",
    "                            #count=count+1\n",
    "                        # grad_diff = grad_diff / grad_count * 1000\n",
    "\n",
    "                        #grad_diff += ((original_pred[item]-pred)**2).sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        grad_diff.backward()\n",
    "                        #print (count)\n",
    "\n",
    "                        #print (dummy_dy_dx)\n",
    "                        #print (original_dy_dx)\n",
    "\n",
    "\n",
    "                        return grad_diff\n",
    "\n",
    "\n",
    "\n",
    "                    optimizer.step(closure)\n",
    "                    if iters % 5 == 0: \n",
    "                        current_loss = closure()\n",
    "                        #if iters == 0: \n",
    "                        #print (\"%.8f\" % current_loss.item())\n",
    "                        #print(iters, \"%.8f\" % current_loss.item())\n",
    "\n",
    "                #     for bat in range(batch-1):\n",
    "                #         history_batch.append(tt(dummy_data[bat].cpu()))\n",
    "\n",
    "                plt.figure(figsize=(30, 20))\n",
    "                for i in range(100):\n",
    "                    plt.subplot(10, 10, i + 1)\n",
    "                    plt.imshow(history[i * 5])\n",
    "                    plt.title(\"iter=%d\" % (i * 5))\n",
    "                    plt.axis('off')\n",
    "                #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "                \n",
    "                #np.savetxt('lfw_ssim_%s'%iter_,percept_dis,fmt=\"%4f\")\n",
    "                #np.savetxt('lfw_mse_%s'%iter_,recover_dis,fmt=\"%4f\")\n",
    "                #plt.savefig(\"./attack_image/index_%s_iter_%s_label_%s\"%(img_index,iter_,torch.argmax(dummy_label, dim=-1).item()))\n",
    "                \n",
    "                plt.clf()\n",
    "            duration = time.process_time()-start\n",
    "            #print (\"Running time is %.4f.\" %(duration/10.0) )\n",
    "            print (\"Duration = \", duration)\n",
    "            \n",
    "            \n",
    "            #if epoch>=1:\n",
    "        #if i==1:\n",
    "            #break\n",
    "        #print (iter_)\n",
    "        inputs,label = data\n",
    "\n",
    "        inputs,label =  Variable(inputs),Variable(label) \n",
    "\n",
    "        optimizer_train.zero_grad()\n",
    "\n",
    "\n",
    "        outputs_benign=net(inputs)\n",
    "        #outputs_benign = F.softmax(outputs_benign, dim=-1)\n",
    "        #print (outputs_benign[0])\n",
    "\n",
    "\n",
    "        loss_benign =  criterion_train(outputs_benign,label)\n",
    "\n",
    "        #print(\"loss computed\")\n",
    "        loss_benign.backward()\n",
    "        #print(\"loss BP\")\n",
    "        optimizer_train.step()\n",
    "\n",
    "        #if i%2000==0:\n",
    "        print (\"Loss Benign = \",loss_benign.item())\n",
    "        #torch.save(net.state_dict(),'./LFW_net.pth')  \n",
    "\n",
    "  \n",
    "        print ('fininshed training')\n",
    "        total = len(y_test)\n",
    "        acc =0.0\n",
    "        for ct in range(total):\n",
    "            testing_data = tt(testing[ct][0].cpu())\n",
    "            testing_data1 = transform(testing_data).to(device)\n",
    "            testing_data2 = testing_data1.view(1, *testing_data1.size())\n",
    "            y_pred = net(testing_data2)\n",
    "            predicted = torch.argmax(y_pred)\n",
    "\n",
    "            if predicted == y_test[ct]:\n",
    "                acc=acc+1\n",
    "        accuracy = acc / total\n",
    "        print (\"accuracy = \",accuracy)\n",
    "        print ('fininshed testing')\n",
    "        print(\"ssim_random2 = \", percept_dis)\n",
    "        print(\"mse_random2 = \", recover_dis)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(60):\n",
    "  plt.subplot(6, 10, i + 1)\n",
    "  plt.imshow(history[i * 5])\n",
    "  plt.title(\"iter=%d\" % (i * 5))\n",
    "  plt.axis('off')\n",
    "print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581348d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccf23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
