{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NWa7Xo6PkIl3",
    "outputId": "b186c3b3-e0cf-423c-922c-94e64702f818"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets.folder import ImageFolder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "from torchvision import models, datasets, transforms\n",
    "import torchvision.transforms.functional as FF\n",
    "from pytorch_msssim import ssim\n",
    "torch.manual_seed(50)\n",
    "import os\n",
    "import time\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ImageFolder(r'C:\\Users\\badha\\OneDrive - Florida International University\\Desktop\\PhD at FIU\\Solid Lab\\Spring 2023\\CPL Attack Paper Exp\\skin11\\melanoma_cancer_dataset\\test')\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "VjKWqs2akepH",
    "outputId": "586bcc5a-f4ea-46ce-b510-edbb20f603ef"
   },
   "outputs": [],
   "source": [
    "dst = ImageFolder(r'C:\\Users\\badha\\OneDrive - Florida International University\\Desktop\\PhD at FIU\\Solid Lab\\Spring 2023\\CPL Attack Paper Exp\\skin11\\melanoma_cancer_dataset\\test')\n",
    "tp = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tt = transforms.ToPILImage()\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "print(\"Running on %s\" % device)\n",
    "\n",
    "def label_to_onehot(target, num_classes=2):\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
    "    onehot_target.scatter_(1, target, 1)\n",
    "    return onehot_target\n",
    "\n",
    "def cross_entropy_for_onehot(pred, target):\n",
    "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AorI020iVjjS"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if hasattr(m, \"weight\"):\n",
    "        m.weight.data.uniform_(-0.5, 0.5)\n",
    "    if hasattr(m, \"bias\"):\n",
    "        m.bias.data.uniform_(-0.5, 0.5)\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5//2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(768, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # print(out.size())\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "net = LeNet().to(device)\n",
    "net.apply(weights_init)\n",
    "criterion = cross_entropy_for_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory=['recovered_image_skin_2024exp/With SGD Optimizer/0','recovered_image_skin_2024exp/With SGD Optimizer/benign','recovered_image_skin_2024exp/With SGD Optimizer/malignant']\n",
    "# directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AS=0\n",
    "whole_time=0\n",
    "sSim=[]\n",
    "mSe=[]\n",
    "count=0\n",
    "for ii in range(0,len(dst),10):\n",
    "    ######### honest partipant #########\n",
    "    print(\"Image: \", count+1)\n",
    "    \n",
    "    img_index = ii\n",
    "    gt_data = tp(dst[img_index][0]).to(device)\n",
    "    gt_data = gt_data.view(1, *gt_data.size())\n",
    "    gt_label = torch.Tensor([dst[img_index][1]]).long().to(device)\n",
    "    gt_label = gt_label.view(1, )\n",
    "    gt_onehot_label = label_to_onehot(gt_label, num_classes=2)\n",
    "\n",
    "    #plt.imshow(tt(gt_data[0].cpu()))\n",
    "    #plt.title(\"Ground truth image\")\n",
    "    #print(\"GT label is %d.\" % gt_label.item(), \"\\nOnehot label is %d.\" % torch.argmax(gt_onehot_label, dim=-1).item())\n",
    "\n",
    "    # compute original gradient \n",
    "    out = net(gt_data)\n",
    "    y = criterion(out, gt_onehot_label)\n",
    "    dy_dx = torch.autograd.grad(y, net.parameters())\n",
    "    \n",
    "    \n",
    "    # share the gradients with other clients\n",
    "    original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
    "    # generate dummy data and label\n",
    "    \n",
    "    start=time.process_time()\n",
    "    dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
    "    dummy_label = torch.randn(gt_onehot_label.size()).to(device).requires_grad_(True)\n",
    "\n",
    "    #plt.imshow(tt(dummy_data[0].cpu()))\n",
    "    #plt.title(\"Dummy data\")\n",
    "    #print(\"Dummy label is %d.\" % torch.argmax(dummy_label, dim=-1).item())\n",
    "    optimizer = torch.optim.LBFGS([dummy_data, dummy_label] )\n",
    "    \n",
    "    history = []\n",
    "    for iters in range(300):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = net(dummy_data) \n",
    "            dummy_onehot_label = F.softmax(dummy_label, dim=-1)\n",
    "            dummy_loss = criterion(pred, dummy_onehot_label) # TODO: fix the gt_label to dummy_label in both code and slides.\n",
    "            dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "\n",
    "            grad_diff = 0\n",
    "            grad_count = 0\n",
    "            for gx, gy in zip(dummy_dy_dx, original_dy_dx): # TODO: fix the variablas here\n",
    "                grad_diff += ((gx - gy) ** 2).sum()\n",
    "                grad_count += gx.nelement()\n",
    "            # grad_diff = grad_diff / grad_count * 1000\n",
    "            grad_diff.backward()\n",
    "\n",
    "            return grad_diff\n",
    "\n",
    "        optimizer.step(closure)\n",
    "        if iters % 100 == 0: \n",
    "            current_loss = closure()\n",
    "            print(iters, \"%.4f\" % current_loss.item())\n",
    "        history.append(tt(dummy_data[0].cpu()))\n",
    "    end=time.process_time()\n",
    "    total_time=end-start\n",
    "    whole_time=whole_time+total_time\n",
    "    # Load the two images (as PIL Images or tensors)\n",
    "    img1 = tp(dst[ii][0]) \n",
    "    img2 = history[299]\n",
    "\n",
    "    # Convert the images to tensors and reshape to (batch_size, channels, height, width)\n",
    "    img1_tensor = img1.unsqueeze(0)\n",
    "    img2_tensor = FF.to_tensor(img2).unsqueeze(0)\n",
    "    \n",
    "    # Calculate SSIM between the two images\n",
    "    ssim_value = ssim(img1_tensor, img2_tensor, data_range=1.0, size_average=True)\n",
    "    sSim.append(ssim_value)\n",
    "    print(f\"SSIM: {ssim_value:.4f}\")\n",
    "    mse = F.mse_loss(img1_tensor, img2_tensor)\n",
    "    mSe.append(mse)\n",
    "    print(f\"MSE: {mse:.8f}\")\n",
    "    print(\"Time Needed: \",total_time)\n",
    "    \n",
    "    \n",
    "#     lbl=[]\n",
    "#     for j in range(0,10):\n",
    "#         lbl.append(j)\n",
    "#     for check in range(0,10):\n",
    "#         if(gt_label.item()==lbl[check]):\n",
    "#             plt.imshow(history[299])\n",
    "#             plt.axis('off')\n",
    "#             print(gt_label.item())\n",
    "#             #plt.savefig(os.path.join(directory[check], f'image_lbl{ii, check}.png'), bbox_inches='tight', pad_inches=0)\n",
    "#             plt.close() \n",
    "        \n",
    "    print()\n",
    "    \n",
    "    if(ssim_value>=.90):\n",
    "        AS=AS+1\n",
    "        #print(AS)\n",
    "    count=count+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sSim)):\n",
    "    print(sSim[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mSe)):\n",
    "    print(mSe[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count\", count)\n",
    "print(\"Attack Success Rate: \", (AS/(count+1)))\n",
    "print(\"Avg. SSIM: \",(np.average(sSim)))\n",
    "print(\"Avg. MSE: \",(np.average(mSe)))\n",
    "print(\"Avg. Time:\", (whole_time/(count+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Deep Leakage from Gradients.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GPU_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
